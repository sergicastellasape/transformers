{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import torch\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "from transformers import *\n",
    "from custom.transformer_sentence import TransformerSentence\n",
    "from custom.chunker import Chunker\n",
    "from custom.funcs import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# LOAD PRETRAINED MODELS (this is the most costly)\n",
    "# Bert base and large, uncased\n",
    "#BertBaseModel = BertModel.from_pretrained('bert-base-uncased')\n",
    "#BertBaseTokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "#BertLargeModel = BertModel.from_pretrained('bert-large-uncased')\n",
    "#BertLargeTokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n",
    "# Scibert uncased\n",
    "SciBertModel = BertModel.from_pretrained('scibert-scivocab-uncased')\n",
    "SciBertTokenizer = BertTokenizer.from_pretrained('scibert-scivocab-uncased')\n",
    "#SciBertBaseVocabModel = BertModel.from_pretrained('scibert-basevocab-uncased')\n",
    "#SciBertBaseVocabTokenizer = BertTokenizer.from_pretrained('scibert-basevocab-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the test dataset from a .txt file into a list of sentences (list of strings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos = torch.nn.CosineSimilarity(dim=1, eps=1e-5) # similarity func.\n",
    "chunker = Chunker(layer=-1, \n",
    "                  sim_function=cos, \n",
    "                  threshold=0.9, \n",
    "                  exclude_special_tokens=True, \n",
    "                  combinatorics='sequential')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'remove_subsets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-4647225b06d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences_obj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repos/zeta-alpha/transformers/custom/chunker.py\u001b[0m in \u001b[0;36mcompact\u001b[0;34m(self, sentence)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTransformerSentence\u001b[0m \u001b[0;31m#, \"Input must be a TransformerSentence Object!\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mindices_to_compact\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices_to_compact_by_similarity_threshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repos/zeta-alpha/transformers/custom/chunker.py\u001b[0m in \u001b[0;36mindices_to_compact_by_similarity_threshold\u001b[0;34m(self, sentence)\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0msimilarities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msim_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcenter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_candidate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mworst_sim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimilarities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mworst_sim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mall_indices_to_compact\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mindices_to_compact\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_subsets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_indices_to_compact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'remove_subsets' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1,
     6,
     47,
     59
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "def remove_subsets(L):\n",
    "    filtered = filter(lambda f: not any(set(f) < set(g) for g in L), L)\n",
    "    return list(filtered)\n",
    "\n",
    "\n",
    "def indices_to_compact_by_similarity_threshold(sequence_embeddings,\n",
    "                                               sim_function=cos,\n",
    "                                               threshold=0.1,\n",
    "                                               exclude_special_tokens=True,\n",
    "                                               combinatorics=None):\n",
    "    # combinatorics= 'sequential', 'all'\n",
    "    seq_length, embedding_size = sequence_embeddings.size() #make sure the input is proper size!!\n",
    "    indices = list(range(seq_length))    \n",
    "    \n",
    "    # Combinations of indices that are group candidates\n",
    "    if combinatorics == 'sequential':\n",
    "        if exclude_special_tokens:\n",
    "            idx_combinations = [indices[s:e] for s, e in itertools.combinations(range(1, len(indices)), 2)]\n",
    "        else:\n",
    "            idx_combinations = [indices[s:e] for s, e in itertools.combinations(range(len(indices)+1), 2)]\n",
    "            \n",
    "    elif combinatorics == 'all':\n",
    "        idx_combinations = []\n",
    "        for L in range(2, seq_length+1):\n",
    "            combinations = list(itertools.combinations(indices, r=L))\n",
    "            idx_combinations.extend(combinations)\n",
    "    else:\n",
    "        raise ValueError('You must specify the combinatorics as \"sequencial\" or \"all\"!!')\n",
    "    \n",
    "    \n",
    "    all_indices_to_compact = []\n",
    "    for indices in idx_combinations:\n",
    "        group_candidate = sequence_embeddings[indices, :]\n",
    "        group_size = len(indices)\n",
    "        center = torch.mean(group_candidate, dim=0)\n",
    "        center = center.repeat(group_size, 1)\n",
    "        # calculate all embeddings similarities w.r.t. the center of the group\n",
    "        similarities = sim_function(center, group_candidate)\n",
    "        worst_sim, _ = torch.min(similarities, dim=0)\n",
    "        if worst_sim > threshold: all_indices_to_compact.append(indices)\n",
    "            \n",
    "    indices_to_compact = remove_subsets(all_indices_to_compact)\n",
    "    \n",
    "    return indices_to_compact\n",
    "\n",
    "\n",
    "def compact_embeddings(original_embeddings, indices_to_compact):\n",
    "    new_embeddings_list = []\n",
    "    for indices in indices_to_compact:\n",
    "        group = original_embeddings[indices, :]\n",
    "        center = torch.mean(group, dim=0)\n",
    "        new_embeddings_list.append(center)\n",
    "        \n",
    "    new_embeddings = torch.stack(new_embeddings_list, dim=0)\n",
    "    \n",
    "    return new_embeddings\n",
    "\n",
    "\n",
    "def chunks_prediction_from_sentence_objects(sentences_obj, thr=0.9, model_layer=-1):\n",
    "    transformer_chunks = [] #this is gonna be a list of lists\n",
    "    for transformer_sentence in sentences_obj:\n",
    "        sentence_tokens = transformer_sentence.summary['input_tokens']\n",
    "        full_representation = transformer_sentence.summary['states'][model_layer, :, :]\n",
    "        indices_to_compact = indices_to_compact_by_similarity_threshold(full_representation,\n",
    "                                                                        sim_function=cos,\n",
    "                                                                        threshold=thr,\n",
    "                                                                        exclude_special_tokens=True,\n",
    "                                                                        combinatorics='sequential')\n",
    "        chunks = []\n",
    "        for chunk_indices in indices_to_compact:\n",
    "            if len(chunk_indices) > 1:\n",
    "                tokens = [sentence_tokens[i] for i in chunk_indices]\n",
    "                # remove leading ## and everything after _ in tokens to match the words\n",
    "                tokens = [re.sub(r'_(.*)', '', token).replace('##', '') for token in tokens]\n",
    "                joint_token = '_'.join(tokens)\n",
    "                chunks.append(joint_token)\n",
    "\n",
    "        transformer_chunks.append(chunks)\n",
    "    return transformer_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "def recall_between_lists(ground_truth, prediction):\n",
    "    recall, total = 0, 0\n",
    "    for i, sentence in enumerate(ground_truth):\n",
    "        for chunk in sentence:\n",
    "            total += 1\n",
    "            if chunk in prediction[i]: recall += 1\n",
    "    return recall / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:34<00:00,  8.83it/s]\n"
     ]
    }
   ],
   "source": [
    "sentences, sentences_obj = load_dataset(txt_path='../datasets/quora_questions.txt',\n",
    "                                       return_embeddings=False,\n",
    "                                       MODEL=SciBertModel,\n",
    "                                       TOKENIZER=SciBertTokenizer)\n",
    "\n",
    "sentences = [sentence.lower() for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Tokenization:  ['[CLS]', 'what', 'is', 'a', 'bayesian', 'neural', 'network', '?', '[SEP]']\n",
      "['what_is_a_bayesian_neural', 'a_bayesian_neural_network', 'neural_network_?']\n"
     ]
    }
   ],
   "source": [
    "s = \"What is a bayesian neural network?\"\n",
    "sentence = TransformerSentence(s)\n",
    "new_embeddings, new_tokens = chunker.compact(sentence)\n",
    "print(new_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download en\n",
    "# Generate the spacy noun chunks as \"ground truth\"!\n",
    "nlp = spacy.load(\"en\") # en_core_web_sm\n",
    "\n",
    "spacy_noun_chunks = [] # this is gonna be a list of lists\n",
    "for sentence in sentences:\n",
    "    doc = nlp(sentence)\n",
    "    chunks = []\n",
    "    for chunk in doc.noun_chunks:\n",
    "        joint_token = str(chunk).replace(' ', '_')\n",
    "        \n",
    "        chunks.append(joint_token)\n",
    "    spacy_noun_chunks.append(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['convolutional_neural_networks', 'tasks', 'image_classification'], ['non-causal_temporal_convolutions', 'the_equivalence'], ['any_techniques', 'rnn/lstm', 'time_series_data'], ['bayesian_inference', 'what', 'a_dirichlet_process', \"layman's_terms\"], ['an_objective_account', 'statistical_inference', 'frequentist_methods', 'bayesian_methods'], ['bayesian_network', 'deep_learning', 'causation'], ['deep_neural_networks', 'the_minimum_function'], ['facial_recognition_tools'], ['neural_networks', 'lstm', 'time_series_prediction'], ['time_series_dynamic_modelling'], [], ['you', 'the_hmm_algorithm'], ['classification', 'machine_learning', 'i', 'a_k-nn_classifier', 'a_naive_bayes_classifier'], ['computer_vision', 'what', 'the_difference', 'hog', 'feature_descriptor'], ['computer_vision', 'what', 'the_difference', 'local_descriptors', 'global_descriptors'], ['convex_optimization', 'what', 'the_advantage', 'direction_method', 'multipliers', 'admm', 'what', 'the_use_case', 'this_type', 'method', 'classic_gradient_descent', 'gradient_descent_method'], ['most_machine', 'algorithms', 'batch', 'they', 'they', 'a_new_bit', 'data'], ['computer_vision', 'object_detection', 'machine_learning'], ['recognition_technology', 'a_person', 'they', 'wrinkles', 'scars', 'cosmetic_surgery', 'example', 'a_facelift'], ['machine_learning', 'more_data'], ['svm', 'it', 'logistic_regression', 'a_non-linear_case'], ['data', 'what_steps', 'one', 'what_distribution', 'poisson', 'gamma', 'beta', 'the_data'], ['energy_based_models', 'deep_learning', 'probability'], ['linear_regression', 'gradient_descent', 'gradient_descent', 'a_type', 'linear_regression', 'it', 'ols', 'least_squares', 'gls'], ['the_monte_carlo_methods', 'an_inference', 'probabilistic_graphical_models'], ['the_parameters', 'a_bayesian_network'], ['how_can_deep_learning', 'benefit', 'bayesian_methods'], ['recognition_algorithms', 'photos'], ['i', 'gaussian_processes', 'regression'], ['computing'], ['a_tpu', 'gpu'], ['recognition_algorithms', 'human_faces'], ['fully_convolutional_networks', 'their_coarse_output'], ['i', 'a_face_recognition', 'opencv_library', 'dlib'], ['i', 'the_computational_time_complexity', 'big-o', 'back_propagation', 'a_feedforward_neural_network'], ['i', 'feature_selection'], ['i', 'svm_kernels'], ['image_recognition_algorithms'], ['we', 'cnn', 'deep_features'], ['you', 'the_value', 'channels', 'you', 'your_cnn'], ['you', 'which_approach', 'a_problem', 'bayesian', 'frequentist'], ['you', 'the_derivative', 'the_cross-entropy_loss_function', 'a_convolutional_neural_network'], ['you', 'the_accuracy', 'a_neural_network'], ['you', 'a_class', 'event_probabilities', 'the_context', 'predictive_modelling'], ['a_conditional_probability', 'poisson', 'exponentials'], ['bayesian_optimization'], ['how_does_bayesian_reasoning_account', 'overfitting'], ['how_does_facial_recognition_deal', 'hair'], ['how_does_facial_recognition_distinguish', 'pictures', 'a_face', 'the_actual_face'], ['fingerprints'], ['how_does_lstm_help', 'the_vanishing', 'gradient_problem', 'a_recurrent_neural_network'], ['how_does_multinomial_naive_bayes_work'], ['ocr'], ['a_neural_network'], ['how_does_the_bayes_classifier_work'], ['the_face_recognition_system', 'a_new_person', 'the_system'], ['the_facial_recognition_algorithms_work', 'an_image', 'all_faces', 'them', 'names'], ['how_does_the_lda_allocation_work'], ['what', 'its_working_model'], ['the_model', 'faster_r-cnn', '50_work'], ['the_perceptual_image', 'you', 'it'], ['how_does_the_region_proposal_network', 'rpn', 'faster_r-cnn_work'], ['the_sliding_window', 'faster_r-cnn'], [], ['someone', 'a_specific_example'], ['how_facial_hair', 'large_beards', 'face_recognition_algorithm'], ['a_convolutional_neural_network', 'invariant_features'], ['graph_theory', 'data_science', 'neural_networks'], ['isotonic_regression', 'practice', 'calibration', 'machine_learning'], ['how_is_lstm', 'rnn'], ['a_layman_explanation'], ['the_hidden_state', 'h', 'the_memory', 'c', 'an_lstm_cell'], ['how_many_layers'], ['how_many_parameters', 'resnet-50'], ['how_many_terms', 'a_bayes_model'], ['classical_machine', 'algorithms', 'svms', 'decision_trees', 'deep_learning'], ['i', 'a_simple_color_recognition_app', 'scratch', 'libraries', 'other_pre-written_code'], ['instance', 'i', 'my_webcam', 'an_object', 'the_name', 'its_color', 'the_screen'], [\"layman's_terms\", 'what', 'the_differences', 'similarities', 'bayes_networks', 'markov_decision_process', 'hidden_markov_models'], [\"layman's_terms\", 'sampling_work'], [\"layman's_terms\"], ['lstm', 'you', 'what_size', 'the_weights'], ['neural_network', 'each_neuron', 'a_hidden_layer', 'a_certain_feature', 'eye', 'example', 'it', 'what', 'an_eye', 'the_meaning', 'eye', 'a_combination', 'eyebrow', 'teeth', 'some_other_combinations'], ['optimization', \"newton's_method\", 'gradient_descent'], ['python_keras', 'you', 'the_output', 'two_different_models', 'it', 'another_model'], ['what_situation', 'i', 'neural_networks', 'machine_learning', 'algorithms'], ['what_situations', 'facial_recognition'], ['what_types', 'situations', 'we', 'vanilla_recurrent_neural_networks', 'lstm'], ['cases', 'grus', 'lstms'], ['what', 'the_difference', 'bayesian_estimation', 'maximum_likelihood_estimation'], ['bayesian_statistics', 'frequentist_statistics'], ['c#_a_good_programming_language', 'image_processing_and_computer_vision'], ['convolutional_neural_network_basically_data-preprocessing', 'kernel', 'neural_networks'], ['just_neural_networks', 'some_pre-processing', 'automated_feature_selections'], [], ['it', 'a_neural_machine_translation_system', 'statistical_mt', 'you', 'all_the_right_ingredients'], ['it', 'a_neural_network'], ['is_lstm', 'a_neural_network'], ['the_architecture', 'text_generation', 'rnns'], ['the_lda_parametric'], ['a_practical_size_limitation', 'convolutional_neural_networks'], ['any_correlation', 'quine’s_underdetermination_and_bayesian_issues', 'old_evidence', 'new_theories'], ['wider_or_deeper_convolutional_neural_networks', 'computer_vision_tasks'], ['many_statistical_tests', 'the_physical_sciences', 'approximations', 'distribution', 'order', 'confidence_levels', 'samples', 'a_larger_population'], ['bayesian_methods'], ['i', 'tensorflow', 'pytorch'], ['algorithms', 'two_images/objects'], ['what', 'factorization_machines', 'they', 'machine_learning'], ['what', 'kernels', 'machine_learning', 'we', 'them'], ['what', 'markov_chain_monte_carlo_methods', \"layman's_terms\"], ['what', 'prior_and_posterior_probabilities'], ['what', 'probabilistic_graphical_models', 'they'], ['what', 'siamese_neural_networks', 'what_applications', 'they'], ['what', 'some_applications', 'probabilistic_graphical_models'], ['what', 'some_benefits', 'drawbacks', 'discriminative_and_generative_models'], ['what', 'some_fundamental_deep_learning_papers', 'code', 'data', 'the_result', 'the_way'], ['what', 'some_good_papers', 'topic_modeling', 'short_texts', 'tweets'], ['what', 'some_interesting_things', 'machine_learning_algorithms', 'few_practicing_data_scientists'], ['what', 'some_intuitive_examples', 'the_bayes'], ['what', 'the_current_challenges', 'self-driving/autonomous_cars', 'computer_vision_context'], ['what', 'some_recent_advances', 'non-convex_optimization_research'], ['what', 'some_unsolved_problems', 'deep_machine_learning'], ['what', 'rnns', 'lstm', 'gru'], ['what', 'some_ways', 'pre-procesing_images', 'convolutional_neural_networks', 'the_task', 'image_classification'], ['what', 'the_advantages', 'bayesian_methods', 'frequentist_methods', 'web_data'], ['what', 'the_advantages', 'convolution'], ['what', 'the_advantages', 'different_classification_algorithms'], ['what', 'the_advantages', 'fully_convolutional_networks', 'cnns'], ['what', 'the_advantages', 'logistic_regression', 'decision_trees'], ['any_cases', 'it', 'logistic_regression', 'decision_trees'], ['what', 'the_algorithms', 'a_point', 'an_arbitrary_closed_shape'], ['what', 'the_applications', 'face_recognition'], ['what', 'the_benefits', 'the_laplace', 'the_gaussian', 'the_bayesian_inference'], ['what', 'the_best_visualizations', 'machine_learning', 'algorithms'], ['what', 'the_current_major_limitations', 'computer_vision'], ['what', 'the_differences', 'dbn', 'cnn'], ['which_one', 'object_detection'], ['what', 'the_differences', 'generative_and_discriminative_machine_learning'], ['what', 'the_disadvantages', 'a_naive_bayes', 'classification'], ['what', 'the_interesting_differences', 'the_total_probability_theory', 'the_bayes_theorem'], ['what', 'the_limits', 'deep_learning'], ['what', 'the_main_differences', 'the_word_embeddings', 'elmo', 'bert', 'word2vec', 'glove'], ['what', 'the_main_drawbacks', 'current_image_segmentation_algorithms'], ['what', 'the_main_operational_problems', 'neural_networks'], ['what', 'the_most_critical_shortcomings', 'computer_vision', 'models', 'robots', 'automation'], ['what', 'the_most_important_problems', 'computer_vision'], ['what', 'the_most_important_problems', 'face_recognition'], ['what', 'the_pros', 'cons', 'a_bayesian_network', 'a_markov_decision_process'], ['what', 'the_pros', 'cons', 'matlab', 'open_cv', 'image_processing'], ['what', 'the_real_life_applications', 'convex_hulls'], ['what', 'the_units', 'lstm_keras'], ['what', 'bad_facial_recognition'], ['what', 'a_1x1_convolutional_layer'], ['what', 'dimensional_reduction', 'a_neural_network'], ['what', 'it', 'all_produced_images', 'a_gan'], ['what', 'max'], ['what', 'the_alpha', 'the_dual_form', 'the_svm_optimization_problem'], ['what', \"'exact_inference\", 'the_context', 'probabilistic_graphical_models'], ['what', '‘variational_inference', 'the_context', 'probabilistic_graphical_models'], ['what', 'a_bayesian_neural_network'], ['what', 'a_convolutional_neural_network'], ['what', 'a_difference', 'one_more_layer', 'neurons', 'one_layer'], ['what', 'a_good_explanation', \"mit's_new_sparse_fast_fourier_transform\", 'non-technical_people'], ['what', 'a_layer', 'tensorflow'], ['what', 'a_neural_network_accelerator'], ['what', 'a_receptive_field', 'a_convolutional_neural_network'], ['what', 'a_sequence_classification', 'lstm'], ['what', 'a_simple_explanation', 'artificial_neural_networks'], ['what', 'a_stochastic_process', \"layman's_terms\"], ['what', 'a_unit', 'lstm'], ['what', 'alpha', 'multinomial_naive_bayes'], ['what', 'an_intuitive_explanation'], ['what', 'an_intuitive_explanation', 'neural_networks'], ['what', 'an_intuitive_explanation', \"bayes'_rule\"], ['what', 'an_intuitive_explanation', 'convolutional_neural_networks'], ['what', 'an_intuitive_explanation', 'fisher_information'], ['what', 'an_intuitive_explanation', 'lstms', 'grus'], ['what', 'an_intuitive_explanation', 'stochastic_gradient_descent'], ['what', 'an_intuitive_explanation', 'the_xavier_initialization', 'deep_neural_networks'], ['what', \"bayes'_law\"], ['what', 'bayesian_inference', 'statistics'], ['bayesian_inference'], ['what'], [], ['what', 'vector_machine_(svm)_classifier'], ['which_algorithm'], ['algorithm', 'reliable_detection', 'unpredictable_situations'], ['what', 'causality'], ['what', 'current_cutting-edge_research', 'bayesian_statistics', 'topics', 'machine_learning'], ['what', 'deep_learning', 'what', 'deep_neural_networks'], ['what', 'differentiable_programming'], ['what', '|_embedded_space', '|', 'deep_neural_architectures'], ['what', 'exactly_the_attention_mechanism', 'rnn', '(recurrent_neural_network'], ['it', 'you', 'it', 'what', \"google's_capsule_network\"], ['it', 'convolutional_neural_networks'], ['what_problems', 'areas', 'neural_network'], ['what', 'it'], ['what', 'lstm', 'keras'], ['what', 'mirror_descent', 'it', 'gradient_descent'], ['what', 'r-cnn'], ['what', 'keras'], ['what', 'softmax', 'cnn'], ['what', 'softmax_regression', 'it', 'logistic_regression'], ['what', \"tesla's_'deep_rain\", 'what', 'it'], ['what', 'the_advantage', 'convolutional_neural_network', '(cnn', 'recurrent_neural_network', 'rnn'], ['what', 'the_best_neural_network_library', 'python'], ['what', 'the_best_ocr_software', 'pdf_files', 'image_text', 'text_files'], ['what', 'the_conceptual_meaning', 'markov_chains'], ['what', 'the_core', 'bayesian_thinking'], ['what', 'the_default_learning_rate', 'keras'], ['what', 'the_difference', 'bayes’_theorem_and_conditional_probability'], ['what', 'the_difference', 'binary_classification', 'bayes_classifier', 'bayes_decision_boundary'], ['what', 'the_difference', 'cnn', 'r-cnn'], ['what', 'the_difference', 'detection', 'classification', 'computer_vision'], ['what', 'the_difference', 'dropout', 'normalization'], ['what', 'the_difference', 'gaussian', 'bayesian'], ['what', 'the_difference', 'hierarchical_recurrent_neural_network', 'lstm'], ['what', 'the_difference', 'image_processing_and_computer_vision'], ['what', 'the_difference', 'linear_convolution', 'circular_convolution'], ['what', 'the_difference', 'logistic_regression', 'naive_bayes'], ['what', 'the_difference', 'ripv1', 'ripv2'], ['what', 'the_difference', 'rnn'], ['what', 'the_difference', 'sfm', 'visual_slam'], ['what', 'the_difference', 'stacked_lstm', 'multidimensional_lstm'], ['what', 'the_difference', 'the_naive_bayes_classifier', 'the_bayes_classifier'], ['what', 'the_difference', 'topic-word', 'document-topic_distribution', 'lda_topical_modeling'], ['what', 'the_difference', 'transfer_learning', 'fine_tuning'], ['what', 'the_formal_explanation', 'why_adversarial_model', 'neural_network'], ['what', 'the_gradient', 'loss_function'], ['what', 'the_hessian_matrix'], ['what', 'it', 'what_reason'], ['what', 'the_intuition', 'bayesian_hierarchical_modeling'], ['what', 'the_learning_rate', 'the_context', 'deep_learning'], ['what', 'the_naive_bayes_classifier', 'machine_learning'], ['what', 'the_necktie_paradox', 'bayesian_statistics'], ['what', 'the_power', 'bayesian_networks'], ['what', 'the_reason', 'convolutional_neural_nets', 'time_series', 'recurrent_neural_nets'], ['what', 'the_relation', 'machine_learning', 'image_processing', 'computer', 'vision'], ['what', 'the_relationship', 'logistic_regression', 'bayes'], ['what', 'the_relationship', 'timestep_and_number_hidden_unit', 'lstm'], ['what', 'the_simplest_explanation', 'bayesian_statistics'], ['what', 'the_smallest_number', 'data_points', 'reliable_machine_learning'], ['what', 'the_tldr', 'spherical_convolutional_neural_networks', 'iclr', '2018_best_paper'], ['what', 'the_vanishing_gradient_problem'], ['what', 'visual_inertial_odometry', 'steps', 'it'], ['what_machine_learning_networks', 'algorithms', 'images', 'gans', '10_training_hours', 'deep_learning', 'just_machine_learning'], ['what', 'model_parameters', 'latent_variables'], ['what_newly_developed_machine_learning_models', 'deep_learning'], ['what_shortcomings', 'you', 'deep_learning'], ['what', 'a_good_way', 'intuition', 'the_lasso', 'l1_regularization', 'sparse_weight_vectors'], ['what', 'the_difference', 'bayesian'], ['frequentist_statistical_approaches', 'simple_laymen_terms'], ['bayesian_inference', 'limitations', 'frequentist_approaches'], ['a_deep_learning_model', '(cnn', 'lstm', 'autoencoder', 'we', 'the_number', 'layers', 'the_number', 'units', 'each_layer', 'sometimes_the_connection', 'them'], ['we', 'mask_r-cnn'], ['the_problem', 'neural_networks'], ['i', 'variational_inference', 'mcmc', 'bayesian_analysis'], ['i', 'an_rnn_lstm', 'arima', 'a_time_series_forecasting_problem'], ['what', 'the_relation', 'them'], ['you', 'random_forest'], ['i', 'the_best_biometrics_facial_recognition_technology', 'id_verification'], ['where_does_each_type', 'neural_network'], ['deep_learning'], ['the_best_image_editing_companies', 'ordinary_images', 'superior_quality_images', 'adobe_photoshop'], ['which_convolutional_network', 'time_series_predictions', 'conv1d', 'conv2d', 'a_cnn_model'], ['which_model', 'the_combination', 'lstm', 'cnn'], ['neural_network_framework', 'keras', 'torch', 'caffe'], ['autoencoders', 'a_failure'], ['what', 'their_alternatives'], ['cnns', 'classification', 'rnns'], ['convolutional_neural_networks', 'other_neural_networks', 'data', 'images', 'video'], ['gpus', 'deep_learning'], ['rnns', 'lstms', 'sentiment_analysis'], ['scikit-learn_machine_learning_models', 'industry', 'tensorflow', 'pytorch'], ['artificial_neural_networks', 'calculation_heavy_sigmoid_function', 'it', 'five_segments'], ['cnns', 'images'], ['why_do_convex', 'optimization_algorithms', 'non-convex_problems', 'machine_learning'], ['deep_learning_models', 'convolutional_layers', 'fully-connected_layers'], ['we', 'a_non-linear_activation_function', 'a_convolutional_neural_network'], ['the_convolution'], [], ['we', 'xgboost', 'random_forest'], ['we', 'naive_bayes_classifiers'], ['a_convex_lens', 'a_bigger_image', 'the_actual_object'], ['normalization', 'averages', 'model_accuracy'], ['detection_accuracy', 'superior_classification_accuracy'], ['bayes'], ['collinearity', 'not_a_problem', 'logistic_regression'], ['gru', 'lstm'], ['it', 'your_inputs', 'gradient_descent'], ['l1_regularization', 'sparsity', 'l2'], ['logistic_regression', 'a_classification_method', 'a_regression_method'], ['logistic_regression', 'naïve_bayes'], ['the_most_common_activation_function', 'neural_networks'], ['the_primal'], ['what_advantages', 'we', 'the_dual'], ['the_frequentist_approach', 'machine', 'the_bayesian_approach'], ['the_output', 'logistic_regression', 'a_probability'], ['the_pooling_layer', 'a_convolution_neural_network'], ['the_pooling_layer', 'cnn'], ['a_saturated_neuron', 'a_problem']]\n"
     ]
    }
   ],
   "source": [
    "print(spacy_noun_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a01fd4a8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "thrs = np.arange(0.80, 1., 0.1)\n",
    "layer = list(range(-1, -3, -1))\n",
    "R = []\n",
    "for L in layer:\n",
    "    recalls = []\n",
    "    for thr in thrs:\n",
    "        tf_chunks = []\n",
    "        for sentence in sentences_obj:\n",
    "            _, t = chunker.compact(sentence, threshold=thr, layer=L)\n",
    "            tf_chunks.append(t)\n",
    "        r = recall_between_lists(spacy_noun_chunks, tf_chunks)\n",
    "        recalls.append(r)\n",
    "    R.append(recalls)\n",
    "\n",
    "\n",
    "for i, recalls in enumerate(R):\n",
    "    plt.plot(thrs, recalls, label=layer[i])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are convolutional neural networks useful for tasks other than image classification?\n",
      "Spacy chunks:  ['convolutional_neural_networks', 'tasks', 'image_classification']\n",
      "Distance-based chunks, thr=0.9: ['convolutional_neural_networks', 'networks_useful', 'useful_for', 'for_tasks', 'other_than', 'image_classification']\n",
      "Are non-causal temporal convolutions the equivalence of Bi-LSTM?\n",
      "Spacy chunks:  ['non-causal_temporal_convolutions', 'the_equivalence']\n",
      "Distance-based chunks, thr=0.9: ['non_-', '-_causal', 'causal_temporal_convolution', 'convolution_s', 's_the', 'the_equivalence', 'equivalence_of', 'of_bi', 'bi_-', 'ls_tm']\n",
      "Are there any techniques, other than RNN/LSTM, to handle time series data?\n",
      "Spacy chunks:  ['any_techniques', 'rnn/lstm', 'time_series_data']\n",
      "Distance-based chunks, thr=0.9: ['there_any', 'any_techniques', 'techniques_,', ',_other', 'other_than', 'rn_n', 'n_/', 'ls_tm', ',_to', 'to_handle', 'handle_time', 'time_series_data']\n"
     ]
    }
   ],
   "source": [
    "thr=0.9\n",
    "tf_chunks = chunks_prediction_from_sentence_objects(sentences_obj, thr=thr, model_layer=-4)\n",
    "for i in range(3):\n",
    "    print(sentences_obj[i].raw_string)\n",
    "    print('Spacy chunks: ', spacy_noun_chunks[i])\n",
    "    print(f'Distance-based chunks, thr={thr}:', tf_chunks[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1, -2, -3, -4, -5, -6, -7, -8, -9]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Tokenization:  ['[CLS]', 'the', 'car', 'broke', 'down', 'while', 'driving', 'in', 'new', 'york', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "s = \"the car broke down while driving in New York.\"\n",
    "tf_sentence = TransformerSentence(s, model=BertBaseModel, tokenizer=BertBaseTokenizer)\n",
    "tf_sentence.write_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Zeta Alpha",
   "language": "python",
   "name": "za_conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
