{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import stanfordnlp\n",
    "import pickle\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from transformers import *\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerSentence():\n",
    "    def __init__(self, sentence_str, \n",
    "                 model=BertModel.from_pretrained('scibert-scivocab-uncased'), \n",
    "                 tokenizer=BertTokenizer.from_pretrained('scibert-scivocab-uncased')):\n",
    "        \n",
    "        self.raw_string = sentence_str\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.summary = {}\n",
    "\n",
    "        \n",
    "    def write_summary(self, input_tokens=None, \n",
    "                      hidden_states=None, \n",
    "                      hidden_attentions=None,\n",
    "                      print_tokens=True):\n",
    "        \n",
    "        if (input_tokens or hidden_states or hidden_attentions) is None:\n",
    "            input_tokens, hidden_states, hidden_attentions = self.forward()\n",
    "        \n",
    "        # this replaces adds a \"_{counter}\" to the repreated tokens, so that \n",
    "        # they can be used uniquely as the keys for the embeddings dictionary\n",
    "        input_tokens = TransformerSentence.make_unique(input_tokens)\n",
    "        \n",
    "        if print_tokens:\n",
    "            print('Sentence Tokenization: ', input_tokens)\n",
    "            \n",
    "        # write summary into the object\n",
    "        self.summary['input_tokens'] = input_tokens\n",
    "        self.summary['states'] = hidden_states\n",
    "        self.summary['attentions'] = hidden_attentions\n",
    "\n",
    "        self.summary['token_embeddings'] = {input_token: hidden_states[:, i, :] \n",
    "                                            for i, input_token in enumerate(input_tokens)}\n",
    "        \n",
    "    def forward(self):\n",
    "        encoded_inputs_dict = self.tokenizer.encode_plus(self.raw_string)\n",
    "        input_ids = encoded_inputs_dict['input_ids']\n",
    "        input_tensor = torch.tensor([input_ids])\n",
    "        input_tokens = [self.tokenizer.decode(input_ids[j]).replace(' ', '') \n",
    "                        for j in range(len(input_ids))]\n",
    "        \n",
    "        final_attention, final_state, hidden_states_tup, hidden_attentions_tup = self.model(input_tensor)\n",
    "        \n",
    "        # stacking states and attentions along the first dimention (which corresponds to the batch when necessary)\n",
    "        hidden_attentions = torch.cat(hidden_attentions_tup, dim=0) # 'layers', 'heads', 'queries', 'keys'\n",
    "        hidden_states = torch.cat(hidden_states_tup, dim=0) # 'layers', 'tokens', 'embeddings'\n",
    "        \n",
    "        return input_tokens, hidden_states.detach(), hidden_attentions.detach()\n",
    "    \n",
    "    \n",
    "    def attention_from_tokens(self, token1, token2, display=True):\n",
    "        input_tokens = self.summary['input_tokens']\n",
    "        \n",
    "        if (token1 and token2) not in input_tokens:\n",
    "            raise ValueError('One or both of the tokens introduced are not in the sentence!')\n",
    "            \n",
    "        idx1, idx2 = input_tokens.index(token1), input_tokens.index(token2)\n",
    "        attention = self.summary['attentions'][:, :, idx1, idx2].numpy()\n",
    "        if display:\n",
    "            TransformerSentence.display_attention(attention, title=(token1, token2))\n",
    "        return attention\n",
    "    \n",
    "    \n",
    "    def attention_from_idx(self, i, j, display=True):\n",
    "        attention = self.summary['attentions'][:, :, i, j].numpy()\n",
    "        if display:\n",
    "            TransformerSentence.display_attention(attention, title=f'Token idx: {(i, j)}')\n",
    "        return attention\n",
    "    \n",
    "    \n",
    "    def save(self, name, path='.'):\n",
    "        with open(os.path.join(path, name), 'wb') as file:\n",
    "            pickle.dump(self, file)\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def visualize_embedding(embedding, title=None, vmax=None, vmin=None):\n",
    "        if (vmax or vmin) is None:\n",
    "            vmax = max(embedding)\n",
    "            vmin = min(embedding)\n",
    "            \n",
    "        N = embedding.size()[0]\n",
    "        h = math.ceil(math.sqrt(N))\n",
    "        # N = a*b where abs(a-b) is minimum\n",
    "        while (N % h != 0):\n",
    "            h -= 1\n",
    "        w = int(N / h)\n",
    "        visualization = embedding.reshape((h, w)).numpy()\n",
    "        fig, ax = plt.subplots()\n",
    "        im = ax.imshow(visualization, vmax=vmax, vmin=vmin)\n",
    "        if title is not None:\n",
    "            ax.set_title(title)\n",
    "        plt.show()\n",
    "    \n",
    "    @staticmethod\n",
    "    def display_attention(attention, title=None):\n",
    "        fig, ax = plt.subplots()\n",
    "        im = ax.imshow(attention, vmin=0., vmax=1.)\n",
    "        if title is not None:\n",
    "            ax.set_title(title)\n",
    "        ax.set_xlabel('HEADS')\n",
    "        ax.set_ylabel('LAYERS')\n",
    "        plt.show()\n",
    "    \n",
    "    @staticmethod\n",
    "    def load(name, path='.'):\n",
    "        with open(os.path.join(path, name), 'rb') as file:\n",
    "            SentenceObject = pickle.load(file)\n",
    "        return SentenceObject\n",
    "    \n",
    "    @staticmethod\n",
    "    def make_unique(L):\n",
    "        unique_L = []\n",
    "        for i, v in enumerate(L):\n",
    "            totalcount = L.count(v)\n",
    "            count = L[:i].count(v)\n",
    "            unique_L.append(v + '_' + str(count+1) if totalcount > 1 else v)\n",
    "        return unique_L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preloading models (this is the most costly)\n",
    "BertBaseModel = BertModel.from_pretrained('bert-base-uncased')\n",
    "BertBaseTokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "BertLargeModel = BertModel.from_pretrained('bert-large-uncased')\n",
    "BertLargeTokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n",
    "SciBertModel = BertModel.from_pretrained('scibert-scivocab-uncased')\n",
    "SciBertTokenizer = BertTokenizer.from_pretrained('scibert-scivocab-uncased')\n",
    "SciBertBaseVocabModel = BertModel.from_pretrained('scibert-basevocab-uncased')\n",
    "SciBertBaseVocabTokenizer = BertTokenizer.from_pretrained('scibert-basevocab-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_sentence = \"Computer Vision: What is the difference between local descriptors and global descriptors\"\n",
    "\n",
    "scibert_sentence = TransformerSentence(raw_sentence,\n",
    "                                       model=SciBertModel,\n",
    "                                       tokenizer=SciBertTokenizer)\n",
    "bert_sentence = TransformerSentence(raw_sentence,\n",
    "                                    model=BertBaseModel,\n",
    "                                    tokenizer=BertBaseTokenizer)\n",
    "bert_large_sentence = TransformerSentence(raw_sentence,\n",
    "                                          model=BertLargeModel,\n",
    "                                          tokenizer=BertLargeTokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scibert_sentence.write_summary(print_tokens=False)\n",
    "bert_sentence.write_summary(print_tokens=False)\n",
    "bert_large_sentence.write_summary(print_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e1i =  scibert_sentence.summary['token_embeddings']['computer'][0,:]\n",
    "e1f =  scibert_sentence.summary['token_embeddings']['computer'][-1,:]\n",
    "e2i =  scibert_sentence.summary['token_embeddings']['vision'][0,:]\n",
    "e2f =  scibert_sentence.summary['token_embeddings']['vision'][-1,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = scibert_sentence.attention_from_tokens('what', 'difference', display=True)\n",
    "_ = bert_sentence.attention_from_tokens('what', 'difference', display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read input sequences from .txt file and put them in a list\n",
    "with open(\"../datasets/quora_questions.txt\") as f:\n",
    "    text = f.read()\n",
    "sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', text)\n",
    "try:\n",
    "    sentences.remove('') # remove possible empty strings\n",
    "except:\n",
    "    None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scibert_sentences = []\n",
    "for raw_sentence in tqdm(sentences):\n",
    "    SentenceObj = TransformerSentence(raw_sentence,\n",
    "                                      model=SciBertModel,\n",
    "                                      tokenizer=SciBertTokenizer)\n",
    "    SentenceObj.write_summary(print_tokens=False)\n",
    "    scibert_sentences.append(SentenceObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sentence in enumerate(scibert_sentences):\n",
    "    print(i, sentence.raw_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scibert_sentences[0].summary['states'][0, :, :].size()\n",
    "\n",
    "# machine learning\n",
    "ml1 = scibert_sentences[12]\n",
    "ml2 = scibert_sentences[16]\n",
    "ml3 = scibert_sentences[17]\n",
    "ml4 = scibert_sentences[19]\n",
    "list_ml = [ml1, ml2 ,ml3, ml4]\n",
    "# computer vision     \n",
    "cv1 = scibert_sentences[13]\n",
    "cv2 = scibert_sentences[14]\n",
    "cv3 = scibert_sentences[17]\n",
    "cv4 = scibert_sentences[91]\n",
    "list_cv = [cv1, cv2, cv3, cv4]\n",
    "# deep learning    \n",
    "dl1 = scibert_sentences[5]\n",
    "dl2 = scibert_sentences[22]\n",
    "dl3 = scibert_sentences[26]\n",
    "dl4 = scibert_sentences[75]\n",
    "list_dl = [dl1, dl2, dl3, dl4]\n",
    "# neural networks\n",
    "nns1 = scibert_sentences[0]\n",
    "nns2 = scibert_sentences[6]\n",
    "nns3 = scibert_sentences[8]\n",
    "nns4 = scibert_sentences[85]\n",
    "nn5 = scibert_sentences[66]\n",
    "nnf6 = scibert_sentences[41]\n",
    "nnf7 = scibert_sentences[53]\n",
    "list_nns = [nns1, nns2, nns3, nns4]\n",
    "# facial recognition\n",
    "fr1 = scibert_sentences[7]\n",
    "fr2 = scibert_sentences[47]\n",
    "fr3 = scibert_sentences[182]\n",
    "fr4 = scibert_sentences[260]\n",
    "list_fr = [fr1, fr2, fr3, fr4]\n",
    "# \n",
    "\n",
    "size = (15, 3)\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=size)\n",
    "fig.suptitle('MACHINE LEARNING')\n",
    "a1 = ml1.attention_from_tokens('machine', 'learning', display=False)\n",
    "a2 = ml2.attention_from_tokens('machine', 'learning', display=False)\n",
    "a3 = ml3.attention_from_tokens('machine', 'learning', display=False)\n",
    "a4 = ml4.attention_from_tokens('machine', 'learning', display=False)\n",
    "\n",
    "axs[0].imshow(a1, vmax=1., vmin=0.)\n",
    "axs[1].imshow(a2, vmax=1., vmin=0.)\n",
    "axs[2].imshow(a3, vmax=1., vmin=0.)\n",
    "axs[3].imshow(a4, vmax=1., vmin=0.)\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos = torch.nn.CosineSimilarity(dim=1, eps=1e-08) # similarity func.\n",
    "sentence = scibert_sentences[23]\n",
    "\n",
    "print(sentence.raw_string)\n",
    "print(sentence.summary['input_tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_evolution = {}\n",
    "for token1 in sentence.summary['input_tokens']:\n",
    "    for token2 in sentence.summary['input_tokens']:\n",
    "        embs1 = sentence.summary['token_embeddings'][token1]#.clamp(-2, 2)\n",
    "        embs2 = sentence.summary['token_embeddings'][token2]#.clamp(-2, 2)\n",
    "        distance_evolution[(token1, token2)] = list(cos(embs1, embs2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, d in distance_evolution.items():\n",
    "    plt.plot(d, alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### SEE EMBEDDING ACROSS LAYERS ####\n",
    "token = 'linear_1'\n",
    "for i in range(13):\n",
    "    embedding = sentence.summary['token_embeddings'][token][i, :]#.clamp(-2, 2)\n",
    "    print(max(embedding), min(embedding))\n",
    "    print('argmax, argmin', torch.argmax(embedding), torch.argmin(embedding))\n",
    "    plt.plot(embedding, alpha=1)\n",
    "    plt.show()\n",
    "    sentence.visualize_embedding(embedding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "az_conda",
   "language": "python",
   "name": "az_conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
